[settings]


## Separate config for each LLM
[defaultllm]
model = "gpt-4-1106-preview"

[synthesis]
model = "gpt-4-1106-preview"
max_tokens = 1000
